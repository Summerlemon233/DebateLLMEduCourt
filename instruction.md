## 项目需求/指示文档：多LLM辩论教育平台 (基础版)

**致：编程主体 LLM Agent**

### 1. 项目概述与目标

你将作为主要的编程主体，负责开发一个基于网页的教育应用。该应用将通过接入多个大型语言模型（LLM），实现用户提问后，多个LLM进行“辩论”，最终由一个“验证者”LLM提供一个经过综合与修正的答案。我们的核心目标是：
*   **教育价值：** 通过展示不同模型的视角和辩论过程，帮助用户理解复杂问题，培养批判性思维，并减少单一LLM带来的幻觉问题。
*   **功能性：** 实现稳定、易用的多LLM问答与辩论流程。
*   **部署：** 网页端部署，易于实现和维护。

### 2. 开发环境与工具

*   **操作系统：** macOS
*   **集成开发环境 (IDE)：** Visual Studio Code (VSCode)
*   **版本控制：** Git (与GitHub仓库集成)
*   **命令行工具：** 请使用标准Unix命令 (如 `mkdir`, `cd`, `ls`)，以及 `npm` 或 `yarn` 进行包管理。

### 3. 技术栈 (已定，请严格遵循)

*   **前端框架：** React.js (配合 Ant Design 或 Material-UI 作为UI组件库)
*   **前端语言：** TypeScript (优先，如果生成JavaScript，我会协助转换为TypeScript)
*   **后端框架：** Node.js + Express.js (部署为 Vercel Serverless Functions)
*   **后端语言：** TypeScript (优先)
*   **LLM API 接入：**
    *   **可调用的服务商：** Google Gemini，DeepSeek，Doubao (字节跳动豆包)，Tencent Hunyuan (腾讯混元)，ChatGLM (智谱清言)，Qwen (阿里云通义千问)。
    *   请从这些服务商中选择 **3-4个作为主要辩论模型** (例如 DeepSeek, Gemini, Qwen)，以及 **1个作为验证者模型** (可以是上述列表中的任何一个，选择一个通用能力较强的模型)。
    *   请封装各自的SDK或HTTP API。
*   **环境变量管理：** `dotenv` (本地开发), Vercel 环境变量 (部署)。
*   **部署平台：** Vercel (同时托管前端静态文件和后端Serverless Functions)

### 4. 核心功能需求 (基础版)

#### 4.1 用户界面 (Frontend)

*   **提问输入区：** 一个文本输入框和一个提交按钮。
*   **模型选择区 (可选)：** 允许用户勾选或选择参与本次辩论的LLM (默认为所有预设模型)。
*   **状态与加载指示：** 在辩论进行时显示友好的加载动画和文字提示 (例如："模型A正在思考...", "模型们正在互相审视...").
*   **结果展示区：**
    *   清晰展示辩论的三个阶段的输出。
    *   **阶段一：** 各个模型**最初**的独立回答。
    *   **阶段二：** 各个模型**互相审视和修正后**的回答。
    *   **阶段三：** **验证者LLM**的最终综合答案和对辩论过程的简要点评。
    *   如果某个LLM回答失败，应有相应的错误提示。

#### 4.2 后端 API (Node.js/Express Serverless Functions)

*   **API Key 管理：**
    *   **重要提示：** 尽管你被告知API Key位于`API_Key.txt`内，但为了项目安全，**绝不能将包含真实API Key的`API_Key.txt`文件提交到GitHub仓库或直接部署。**
    *   **你的代码不应直接读取`API_Key.txt`。**
    *   在本地开发时，API Key应从 `.env` 文件中加载 (`dotenv` 库)。
    *   在部署到 Vercel 时，API Key 必须通过 Vercel 的环境变量界面进行配置。
    *   我将负责将 `API_Key.txt` 中的 Key **手动**配置到 `.env` 和 Vercel 环境变量中。你的任务是确保代码通过 `process.env.YOUR_API_KEY_NAME` 的方式安全地获取这些Key。
*   **LLM API 封装：**
    *   为每个可用的LLM服务商 (Google Gemini, DeepSeek, Doubao, Tencent Hunyuan, ChatGLM, Qwen) 封装一个独立的客户端。
    *   **你可以去互联网搜索这些服务商正确调用API的方式和官方SDK的使用方法。** (例如：Gemini的 `google-generative-ai` SDK，DeepSeek的 `deepseek-chat` 或通用的 `openai` 库兼容方式等)。
    *   处理API请求、响应解析和错误处理（如速率限制、认证失败、网络超时等）。
*   **核心辩论逻辑 (`debate` API Endpoint):**
    *   设计一个 `/api/debate` 或类似命名的 POST endpoint，接收用户问题。
    *   **内部流程 (关键):**
        1.  **阶段一：初始提案 (Initial Proposals)**
            *   接收用户问题 `[User Question]`。
            *   并行向 `LLM_A`, `LLM_B`, `LLM_C` (从已选择的辩论模型中选取) 发送相同的 `[User Question]`。
            *   **Prompt 指示：** "请作为一位经验丰富的专家，根据您所了解的知识，提供关于 '`[User Question]`' 的详细回答。请力求准确、全面。请不要包含任何冗余的开场白或结束语。"
            *   收集并存储 `Answer_A_initial`, `Answer_B_initial`, `Answer_C_initial`。
        2.  **阶段二：交叉审视与自我修正 (Cross-Examination & Self-Correction)**
            *   对于每个参与辩论的LLM，将其**自己的初始答案**和**其他所有LLM的初始答案**作为上下文，要求其进行审视和修正。
            *   **Prompt 指示示例 (对于LLM_A):**
                ```text
                用户的问题是："`[User Question]`"

                您最初的回答是：
                ```text
                [Answer_A_initial]
                ```

                现在请参考其他模型给出的回答：
                - 模型B的回答：```text [Answer_B_initial] ```
                - 模型C的回答：```text [Answer_C_initial] ```

                请您仔细审视您自己的回答和这些参考回答。您的任务是：
                1. 批判性地评估所有回答的准确性、完整性和逻辑一致性。
                2. 指出其他模型回答中可能存在的错误、遗漏或可以补充之处。
                3. 根据您的判断，对您自己的回答进行修正、补充或优化，使其更准确、更全面，并减少潜在的幻觉。
                4. 请清晰地说明您做了哪些修正，以及为什么。请避免冗余的开场白或结束语，直接给出修正后的内容和理由。
                ```
            *   收集并存储 `Answer_A_refined`, `Answer_B_refined`, `Answer_C_refined`。
        3.  **阶段三：最终验证与综合 (Final Verification & Synthesis)**
            *   将用户问题和所有修正后的答案发送给一个独立的**验证者LLM** (`LLM_V`，从已选择的验证模型中选取)。
            *   **Prompt 指示示例 (对于LLM_V):**
                ```text
                用户的问题是："`[User Question]`"

                以下是三位模型经过内部辩论和互相修正后给出的最终回答：
                - 模型A的修正回答：```text [Answer_A_refined] ```
                - 模型B的修正回答：```text [Answer_B_refined] ```
                - 模型C的修正回答：```text [Answer_C_refined] ```

                请您作为一位中立、客观且知识渊博的“总编辑”或“仲裁者”，仔细审查这些回答。您的任务是：
                1. **评估与指出：** 评估它们的准确性、完整性和一致性。指出其中可能存在的任何剩余的幻觉、不准确、偏颇或误导信息。
                2. **综合总结：** 综合所有正确、有价值和互补的信息，形成一个最准确、最全面且易于理解的最终答案。如果模型之间存在无法调和的、明显的、且关键的分歧，请明确指出这些分歧点，并尝试解释可能的原因。
                3. **简要点评：** 简要评价本次辩论过程，例如模型们是否有效互相修正了错误，或者有哪些亮点/不足。

                请提供一个结构化的最终答案，可以包含标题和分点。请避免冗余的开场白或结束语。
                ```
            *   返回 `Final_Synthesized_Answer`。

*   **错误处理与重试：** 对LLM API 调用实现健壮的错误处理机制（例如，网络错误、速率限制），并包含基本的重试逻辑（带指数退避）。
*   **状态管理：** 后端需要有效管理每轮辩论的状态和上下文，确保正确传递。

#### 4.3 部署

*   **Vercel 配置：** 提供必要的 `vercel.json` 配置或指导，确保前端静态文件和后端Serverless Functions能正确部署。
*   **环境变量：** 确保Vercel上的环境变量配置与代码中的获取方式一致。

### 5. LLM Agent 开发工作流与协作指南 (与我交互方式)

1.  **分阶段交付：** 请不要一次性生成所有代码。我需要你分阶段、模块化地生成和解释代码，以便我进行审查和反馈。
    *   **初始阶段：** 先提供项目结构建议和基础环境配置（`package.json`, `.gitignore`, `tsconfig.json`, Vercel配置）。
    *   **前端骨架：** 再提供React UI的骨架代码（输入框、展示区、加载状态）。
    *   **后端基础：** 接着是后端Express API的入口和LLM客户端封装。
    *   **核心逻辑：** 最后是核心辩论逻辑的实现（分阶段一、二、三）。
2.  **代码解释：** 每次提供代码时，请附上清晰的解释，说明代码的目的、主要功能、如何使用以及需要注意的地方。
3.  **提问与澄清：** 如果在理解需求或实现过程中遇到任何疑问或不确定性，请随时提问并寻求我的澄清。
4.  **迭代与修正：** 我会审查你提供的代码，并提供反馈和修改建议。请根据我的反馈进行迭代和修正。
5.  **Git 提交风格：** 当代码达到一个可测试的小阶段时，请模拟Git提交，提供`commit message`，说明本次提交的内容。

### 6. 非功能性需求

*   **安全性：** LLM API Keys 必须安全存储在后端环境变量中，绝不允许出现在前端代码或版本控制中。
*   **性能：** LLM API 调用应尽可能并行进行 (`Promise.all`等)，以减少等待时间。前端响应迅速，避免卡顿。
*   **用户体验：** 界面清晰，交互流畅，提供友好的加载和错误提示。
*   **代码质量：** 生成的代码应清晰、模块化、可读性高，遵循TypeScript/JavaScript最佳实践。
*   **可维护性：** 代码结构应便于后续扩展和维护。
*   **错误处理：** 所有API调用和业务逻辑应包含适当的错误处理，防止程序崩溃。

### 7. 约束与排除 (基础版暂不包含)

*   不涉及用户身份验证、登录、注册。
*   不涉及数据库存储（用户历史、辩论结果等）。
*   不涉及RAG (Retrieval Augmented Generation) 外部知识检索。
*   不涉及复杂的图表或可视化辩论过程。
*   不涉及多语言支持。

### 8. 交付物

*   一个完整的、可部署到Vercel的React + Node.js (Serverless) 项目代码库。
*   清晰的README文件，包含项目设置、运行和部署指南。
*   在开发过程中，通过交互式对话提供每个模块的代码和解释。

---

### 9. 你的初始行动

请从项目结构设计开始。请提供一个合理的项目目录结构建议，包括前端、后端（api functions），以及必要的配置文件（`package.json`, `tsconfig.json`, `.gitignore`等），并简要说明其目的。

期待与你合作！